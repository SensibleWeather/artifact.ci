name: upload artifact action
description: Drop in replacement for actions/upload-artifact which provides a browsable link to the artifact
inputs:
  path:
    description: A file, directory or wildcard pattern that describes what to upload
    required: true
  name:
    description: Name of the artifact to upload
    required: false
    default: artifact
  origin:
    description: The origin of the server to upload the artifact to
    required: false
    default: https://www.artifact.ci
  github-token:
    description: The GitHub token to use for the upload
    required: false
runs:
  using: composite
  steps:
    - shell: bash
      run: echo "::group::Upload artifact"
    - name: upload
      uses: actions/upload-artifact@v4
      with:
        name: ${{ inputs.name }}
        path: ${{ inputs.path }}
    - name: Checkout artifact.ci
      uses: actions/checkout@v4
      with:
        repository: mmkal/artifact.ci
        path: tmp/artifact.ci
    - name: install
      shell: bash
      run: corepack enable && pnpm install --silent
      working-directory: tmp/artifact.ci
    - name: patch @vercel/blob for debugging
      shell: bash
      working-directory: tmp/artifact.ci
      run: |
        node -v
        # sed -i 's/const res = await _undici.fetch.call/console.log("client.cjs fetching", {url, options, event});const res = await _undici.fetch.call/g' node_modules/@vercel/blob/dist/client.cjs
        # vercel_chunk_name=$(ls node_modules/@vercel/blob/dist | grep chunk | grep .cjs | grep -v .map)
        # vercel_chunk_cjs="node_modules/@vercel/blob/dist/$vercel_chunk_name"
        # echo "vercel_chunk_cjs: >>>$vercel_chunk_cjs<<<"
        # sed -i 's/const apiResponse/const logFetch = (...args) => {console.log("apiResponse fetching", ...args, {a: args[1]?.headers?.authorization?.split(" ")}); return _undici.fetch(...args)}; const apiResponse/g' $vercel_chunk_cjs
        # sed -i 's/_undici.fetch.call/logFetch.call/g' $vercel_chunk_cjs
        # sed -i 's/res.ok/(res.ok || console.log(await res.clone().text(), res.url, res.status))/g' node_modules/@vercel/blob/dist/client.cjs
        # sed -i 's/return clientToken/console.log({clientToken}); return clientToken/g' node_modules/@vercel/blob/dist/client.cjs
    - name: upload blob
      uses: actions/github-script@v6
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
      with:
        script: |-
          const inputs = ${{ toJson(inputs) }}

          const cwd = process.cwd()
          process.chdir('tmp/artifact.ci')

                const dependencies = {
                  fs: require('fs'),
                  fsPromises: require('fs/promises'),
                  mimeTypes: require('mime-types'),
                  vercelBlobClient: require('@vercel/blob/client'),
                  glob, // ambient variable available from actions/github-script
                }
              
          process.chdir(cwd)


                const __name = (fn, value) => {
                  // for some reason tsx .toString() relies on this
                  Object.defineProperty(fn, 'name', {value})
                  return fn
                }
              
          async function upload({context,inputs,dependencies}){const{glob,mimeTypes,fsPromises:fs,fs:fsSync,vercelBlobClient}=dependencies;const githubToken=inputs["github-token"];Object.assign(global,{window:{location:new URL(inputs.origin)}});const stat=await fs.stat(inputs.path).catch(e=>{if(e.code==="ENOENT")return null;throw e});const globPattern=stat?.isDirectory()?`${inputs.path}/**/*`:inputs.path;const globber=await glob.create(globPattern);const files=await globber.glob();const filesWithPathnames=files.flatMap(f=>{if(!fsSync.statSync(f).isFile())return[];return{localPath:f.replace(process.cwd()+"/",""),multipart:false}});const pathnameToFile=new Map(filesWithPathnames.map(f=>[f.localPath,f]));const redactedContext={...context,runAttempt:Number(process.env.GITHUB_RUN_ATTEMPT),repository:process.env.GITHUB_REPOSITORY,githubOrigin:process.env.GITHUB_SERVER_URL,...{payload:null,payloadKeys:Object.keys(context.payload)}};const bulkRequest={type:"bulk",callbackUrl:`${inputs.origin}/artifact/upload/signed-url`,clientPayload:{githubToken,commit:{ref:context.ref,sha:context.sha,actions_run_id:context.runId.toString()},context:redactedContext},files:filesWithPathnames};if(filesWithPathnames.length===0){throw new Error("No files to upload")}console.log(`Sending bulk request to ${inputs.origin}/artifact/upload/signed-url (${filesWithPathnames.length} files)`);const chunk=__name((list,size)=>{const chunks=[];for(let i=0;i<list.length;i+=size){chunks.push(list.slice(i,i+size))}return chunks},"chunk");const chunked=chunk(bulkRequest.files,5).map(chunkOfFiles=>{return{...bulkRequest,files:chunkOfFiles}});for(const[i,bulkRequest2]of chunked.entries()){console.log(`Uploading chunk ${i+1} of ${chunked.length}`);const res=await fetch(`${inputs.origin}/artifact/upload/signed-url`,{method:"POST",body:JSON.stringify(bulkRequest2),headers:{"content-type":"application/json","user-agent":"artifact.ci/action"}});console.log("response::::",res.status,Object.fromEntries(res.headers));const responseText=await res.clone().text().catch(String);console.log("responseText::::",responseText.slice(0,100));try{if(!res.ok)throw new Error(`failed to upload: ${res.status} ${responseText}`);const data=await res.json();if(!data?.results?.length)throw new Error("no results: "+responseText);for(const result of data.results){const file=pathnameToFile.get(result.localPath);if(file?.localPath!==result.localPath)throw new Error(`local path mismatch: ${file?.localPath} !== ${result.localPath}`);await vercelBlobClient.put(result.pathname,await fs.readFile(file.localPath),{access:"public",token:result.clientToken,multipart:file.multipart});console.log("Uploaded: "+result.viewUrl)}console.log("Upload complete");return}catch(e){console.log("response::::",res.status,responseText);console.log("error::::",e);throw e}}}

          await upload({context, inputs, dependencies})
    - name: cleanup
      shell: bash
      run: rm -rf tmp/artifact.ci
